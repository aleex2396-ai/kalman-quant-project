# Maximum Likelihood Estimation (MLE) Logic

## The Concept
In the Ornstein-Uhlenbeck model, we established that the spread $X_t$ evolves according to a specific decay formula. However, this formula relies on three unknown parameters:
1. $\theta$ (Mean Reversion Speed)
2. $\mu$ (Long-Term Equilibrium)
3. $\sigma$ (Volatility)

We cannot know these values in advance. We must estimate them from the noisy data. We use **Maximum Likelihood Estimation (MLE)** to find the parameters that maximize the probability that the observed historical data was generated by our model.

## The Objective Function
We treat the prediction error ($\epsilon$) as a Gaussian random variable. The probability density function (PDF) for a single step is:

$$f(X_t | X_{t-1}) = \frac{1}{\sqrt{2\pi Q}} \exp\left( -\frac{(X_t - E[X_t])^2}{2Q} \right)$$

Where:
* **$E[X_t]$** is the expected value from our SDE derivation (The "Physics" prediction).
* **$Q$** is the variance derived in the SDE solution (The "Process Noise").

## The Optimization Loop
Instead of maximizing Likelihood directly, we minimize the **Negative Log-Likelihood (NLL)**, which is computationally stable. This transforms the problem into a minimization task, similar to finding the lowest energy state in a chemical system.

$$J(\theta, \mu, \sigma) = \sum_{t=1}^{N} \left( \ln(Q) + \frac{(X_t - E[X_t])^2}{Q} \right)$$

Our Python script will use `scipy.optimize.minimize` to find the $\theta, \mu, \sigma$ that make $J$ as small as possible.
